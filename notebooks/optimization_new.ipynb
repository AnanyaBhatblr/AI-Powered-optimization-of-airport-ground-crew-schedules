{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv('../data/predictions_output.csv')\n",
    "task_priorities_df = pd.read_csv('../data/task_priority_assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "def prepare_data(predictions, priorities):\n",
    "    # Clean and merge data\n",
    "    merged_data = predictions.merge(\n",
    "        priorities[['task_ID', 'priority', 'crew_required']].drop_duplicates(),\n",
    "        left_on='Task_ID',\n",
    "        right_on='task_ID'\n",
    "    )\n",
    "    return merged_data\n",
    "def prepare_data(predictions, priorities):\n",
    "    # Clean and merge data\n",
    "    merged_data = predictions.merge(\n",
    "        priorities[['task_ID', 'priority', 'crew_required']].drop_duplicates(),\n",
    "        left_on='Task_ID',\n",
    "        right_on='task_ID'\n",
    "    )\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_assignments(data):\n",
    "    # Create optimization model\n",
    "    prob = LpProblem(\"Task_Reallocation\", LpMinimize)\n",
    "    \n",
    "    # Get unique values\n",
    "    tasks = data['Task_ID'].unique()\n",
    "    gates = data['Gate_number'].unique()\n",
    "    shifts = data['Shift_no'].unique()\n",
    "    \n",
    "    # Decision variables\n",
    "    x = LpVariable.dicts(\"assign\", \n",
    "                        ((t, g, s) for t in tasks for g in gates for s in shifts),\n",
    "                        cat='Binary')\n",
    "    \n",
    "    # Objective function\n",
    "    prob += lpSum(x[t, g, s] * abs(data.loc[\n",
    "        (data['Task_ID'] == t) & \n",
    "        (data['Gate_number'] == g) & \n",
    "        (data['Shift_no'] == s), 'Predicted'].values[0])\n",
    "        for t in tasks for g in gates for s in shifts)\n",
    "    \n",
    "    # Add constraints\n",
    "    for t in tasks:\n",
    "        prob += lpSum(x[t, g, s] for g in gates for s in shifts) <= data[\n",
    "            data['Task_ID'] == t]['crew_required'].iloc[0]\n",
    "    \n",
    "    for g in gates:\n",
    "        for s in shifts:\n",
    "            prob += lpSum(x[t, g, s] for t in tasks) <= 1\n",
    "            \n",
    "    # Solve\n",
    "    prob.solve()\n",
    "    return prob, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_assignments(results_df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(\n",
    "        results_df.pivot(\n",
    "            index='Task_ID', \n",
    "            columns='Shift_no', \n",
    "            values='Assigned_Value'\n",
    "        ),\n",
    "        cmap='YlOrRd',\n",
    "        annot=True\n",
    "    )\n",
    "    plt.title('Task Assignments by Shift')\n",
    "    plt.tight_layout()\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['task_ID', 'Floor_No', 'Gate_number', 'Criticality',\n",
      "       'Number_of_Personnel', 'Cluster', 'Unnamed: 6'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['priority', 'crew_required'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_data\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_priorities_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Call optimize_assignments with correct input\u001b[39;00m\n\u001b[1;32m     17\u001b[0m optimization_model, assignments \u001b[38;5;241m=\u001b[39m optimize_assignments(merged_data)\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(predictions, priorities)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_data\u001b[39m(predictions, priorities):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Clean and merge data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     merged_data \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m----> 8\u001b[0m         \u001b[43mpriorities\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtask_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpriority\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrew_required\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates(),\n\u001b[1;32m      9\u001b[0m         on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_ID\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure column exists in both dataframes\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_data\n",
      "File \u001b[0;32m~/Documents/mainel/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/mainel/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/mainel/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['priority', 'crew_required'] not in index\""
     ]
    }
   ],
   "source": [
    "# Inspect columns in task_priorities_df\n",
    "print(task_priorities_df.columns)\n",
    "\n",
    "# Update prepare_data function to use correct column names\n",
    "def prepare_data(predictions, priorities):\n",
    "    # Clean and merge data\n",
    "    merged_data = predictions.merge(\n",
    "        priorities[['task_ID', 'priority', 'crew_required']].drop_duplicates(),\n",
    "        on='task_ID'  # Ensure column exists in both dataframes\n",
    "    )\n",
    "    return merged_data\n",
    "\n",
    "# Run optimization\n",
    "merged_data = prepare_data(predictions_df, task_priorities_df)\n",
    "\n",
    "# Call optimize_assignments with correct input\n",
    "optimization_model, assignments = optimize_assignments(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmerged_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGate_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShift_no\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "results = []\n",
    "for t in merged_data['task_ID'].unique():\n",
    "    for g in merged_data['Gate_number'].unique():\n",
    "        for s in merged_data['Shift_no'].unique():\n",
    "            if value(assignments[t, g, s]) > 0:\n",
    "                results.append({\n",
    "                    'Task_ID': t,\n",
    "                    'Gate_number': g,\n",
    "                    'Shift_no': s,\n",
    "                    'Assigned_Value': value(assignments[t, g, s])\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plot_assignments(results_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('optimized_schedule.csv', index=False)\n",
    "print(\"Optimization complete! Schedule saved to optimized_schedule.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
